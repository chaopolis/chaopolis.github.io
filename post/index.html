<!DOCTYPE html>

<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width">
	<title>Chaopolis</title>
	<link rel="profile" href="http://gmpg.org/xfn/11">
	<!--[if lt IE 9]>
	<script src="/js/html5.js"></script>
	<![endif]-->
    
    <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Chaopolis" />

    <link rel='stylesheet' id='twentyfourteen-lato-css'  href='//fonts.googleapis.com/css?family=Lato%3A300%2C400%2C700%2C900%2C300italic%2C400italic%2C700italic&#038;subset=latin%2Clatin-ext' type='text/css' media='all' />

    <link rel='stylesheet' id='genericons-css' href='/genericons/genericons.css' type='text/css' media='all' />
	<link rel='stylesheet' id='twentyfourteen-style-css' href='/css/style.css' type='text/css' media='all' />
	
	<script type='text/javascript' src='/js/jquery/jquery.js'></script>
	<script type='text/javascript' src='/js/jquery/jquery-migrate.min.js'></script>
	<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
</head>

<body class="home blog masthead-fixed list-view full-width grid">
<div id="page" class="hfeed site">
	<header id="masthead" class="site-header" role="banner">
		<div class="header-main">
			<h1 class="site-title"><a href="/index.html" rel="home">Chaopolis</a></h1>

			<div class="search-toggle">
				<a href="#search-container" class="screen-reader-text">Search</a>
			</div>

			<nav id="primary-navigation" class="site-navigation primary-navigation" role="navigation">
				<button class="menu-toggle">Primary Menu</button>
				<a class="screen-reader-text skip-link" href="#content">Skip to content</a>
				<div class="nav-menu">
					<ul>
						
					</ul>
				</div>
			</nav>
		</div>

		<div id="search-container" class="search-box-wrapper hide">
			<div class="search-box">
                <script type="text/javascript">
    function site_search(obj) {
    	var host = window.location.host;
        obj.q.value = "site:" + host + " " + obj.ss_q.value;
    }
</script>

<aside id="search-3" class="widget widget_search">
	<form role="search" class="search-form" action="//www.google.com/search" method="get" onSubmit="site_search(this)">

	<input name="q" type="hidden" />
	    <label>
	        <span class="screen-reader-text">Search for:</span>
	        <input name="ss_q" type="text" placeholder="Search ..." class="search-field" />
	    </label>
	    <input type="submit" value="Search" class="search-submit" />
	</form>
</aside>
			</div>
		</div>
	</header>

	<div id="main" class="site-main">


<div id="main-content" class="main-content">

	<div id="primary" class="content-area">
		<div id="content" class="site-content" role="main">

			<header class="archive-header">
				<h1 class="archive-title">Posts Archive</h1>
			</header>

			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
                <a href="/categories/theory/index.html" rel="category">Theory</a>
                
			</span>
		</div>

		<h1 class="entry-title">NEATL Theory 1: Introducing Neuroeconomics</h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="/post/neatl1-theory//index.html" rel="bookmark">
					<time class="entry-date" datetime="2017-07-08 16:07:19 &#43;0900 JST">
						July 8
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p><strong>I. Motivations for and Goals of NEATL Theory, and an Important Caveat</strong></p>

<p>A Neuroeconomic Approach to Language, what I&rsquo;ll call NEATL Theory, is a theory or set of ideas about the neurophysiology of structured
(or &ldquo;meaningful&rdquo;) volitional action, focusing particularly on the mechanics of motivation and value, to describe and explain language use.
It combines a number of ideas. Most simply, it is an attempt to model and explain
the mechanics of language through the structures, concepts, and approaches of neuroeconomics, a field developed by Paul Glimcher and others.
Neuroeconomics is &ndash; to start with a grossly oversimplifying gist &ndash; a framework using the structure and mechanics of
&ldquo;decision-making&rdquo; cortical maps, as they represent the utility of plans and trigger them into action, and their support mechanisms
(most importantly meta-action maps) to manifest (and thereby explain) voluntary action
of humans and animals and the (internal) structures and conditions under which it operates.</p>

<p>NEATL Theory doesn&rsquo;t refer to neuroeconomics as it is now, but with some proposed extensions and with the addition
of other approaches, such as action theory, attention theory, and child development. It is also, at this early point, not really designed
to be a compelte and robust explanatory theory, but more of set of ideas or guidelines to thinking about the mechanics of volition, language, and meaning and all the pieces
that will have to go into it. That is, it offers a way to think about the mechanics of language from an operational perspectie of interconnected
functional mechanisms and not a formal system of symbols, lines, and boxes on paper.</p>

<p>We can then think about using that idealized framework to describe and explain any kind of animal &amp; human activity.
For humans, the most important category of volitional action to construct and explain is language.
Actions do not have purposeful meaning until that structure is in place.
In that respect, the mechanics of NEATL theory, via first language acquisition, offer a way to think about
volition, personal identity, and free will, contrasted to the non-bootstrapped action of other animals and
prelinguistic humans.</p>

<p>The word &ldquo;approach&rdquo; (the A in NEATL) can have three meanings which respond to the needs for a base framework for human action.
The first is that neuroeconomics is not only a set of findings and theories about human action,
it&rsquo;s also a way of thinking about how to study, explain, and talk about categories of human action and volition at all.
One of the core ideas of neuroeconomic methodology is knitting together levels of explanation of human action, such that
higher level phenomena can be explained in terms of lower-level mechanics, and understanding lower-level mechanics according
to their higher-level functions. Each direction guides the other.</p>

<p>The second idea is that neuroeconomics defines a foundation of low-level mechanisms for human action and there is a long road
from that foundation to full-blooded language as a category of action. The approach is then the set of ideas one would need
to get from the neuroeconomic foundation to the linguistic penthouse.<br />
The suggestion is that there are dozens to hundreds of floors to cover, although they are not necessarily heirarchically ordered.</p>

<p>Inside the penthouse is a brand of cognitive linguistics, which may take inspiration from current strains of cog linguistics but
as built independently from the ground-up &ndash; it&rsquo;s mechanics should arise naturally from the mechanics of the underlying floors and not from some other theories top-down.
At best we can try to reconstruct other theories&rsquo; mechanics through the NEATL mechanics. We can call this neuroeconomic linguistics (NEL) to distinguish it from
formal vanilla cognitive linguistics (which is generally not particularly attune to actual cognitive mechanisms).</p>

<p>&ldquo;Approach&rdquo; can have a third meaning which combines the previous two. One core feature of a NEL is that it has built within it
all the lower-levels of mechanics it took to arrive at the theory, and it obliges any
person modeling the meaning of sentences to reconstruct the meaning in terms of that trip to get there, at least in broad relevant strokes,
passing from level to level up to the linguistic practice, each level knit to the next.</p>

<p><strong>A Big Caveat &ndash; General Theories of Cognition in the Time of Skepticism</strong></p>

<p>I&rsquo;m going to make a separate <u>post</u> about why this is a bad time for developing grand general theories of cognition,
and why I am making an effort to talk about one anyway. This little section is a bit of a rambling summary of it.</p>

<p>Basically, cognitive science is still a relatively recent field. The major findings are across a spectrum of confidence levels.
The findings that seem to have the highest levels of confidence are for rather narrow domains of cognition, priming, the limits of memory, sensory sensitivity, etc.
Theories about high-level complex cognition seem to run into familiar problems that, to me, are maybe best characterized by the
exploiding activation problem or &ldquo;completeness&rdquo; problem in AI. So many different mechanisms get activated in tangled and complex ways for general cognition that
it&rsquo;s difficult to disentangle them. And to try to operate or describe the system without disentangling them can crash the system, so to speak.
But to work with toy systems which don&rsquo;t bring in every system leads to either garbage output or sensible output only in the narrowest
of domains. You either have an entire universe of mechanisms interlinked or next to nothing; it&rsquo;s hard to have general cognition with a theory that can connect
all the pieces full blown.
So that&rsquo;s one of the major challenges that make it difficult to develop or test theories of general cognition, of which this is one.</p>

<p>I am still interested in developing this project because I think it offers a way of thinking about the issues of motivation, volition, and language in a
consistent way, based on a set of general principles that have at least some empirical basis, and seeing how far
we can get building off of them. One thing I liked about Glimcher&rsquo;s work in neuroeconomics, out of which this builds, is that he had clever ways of
turning complexity across domains from a challenge to an asset. Once we have a set of robust findings across different
domains of behavior (economics, behavioral psychology, sociobiology, linguistics, etc.), we can try to build a theory which tries to consistently
operationalize them. That is, the findings can mutually restrict the mechanisms, until one is left with a good idea of
the kinds of mechanisms that could operate across the domains. To do this still takes some interpretion and is far from automatic work.
One has to be willing to sacrifice some sacred cows (that utility either doesn&rsquo;t exist or cannot be directly measured in economics, that grammar is
an innate structure in Chomskyan-inspired linguistics, that the brain is organized by self-contained modules, etc.) in order
to get the pieces to fit together. But to do that requires one to have opinions about which ideas in domains should be kept and
made consistent with ideas from other domains, and which ones should be sent to the chopping block in order to get barriers
out of the way which keep us from seeing how the pieces interconnect.</p>

<p>Well-established empirical findings should always be privileged. But moving into findings that
are more complex and difficult to interpret, I think a good strategy is to consider the pieces across various domain as designed
 to be working from the same system, and read them in terms of each other, which suggests consistent approaches that
 wouldn&rsquo;t be as visible if one were looking only from the perspective of one domain. So that&rsquo;s the proposed virtue
 of trying to unify ideas across major fields, in this case, neurophysiology, behavioral psychology, microeconomics,
 and cognitive linguistics. This theory builds off the idea that all of these fields are different levels of explanation of the
 same underlying mechanisms of volitional action in humans. And they each already have general principles which offer ideas about how to integrate them.</p>

<p>I am building this theory by following these principles and ideas from a set of related fields which seem to me to be
proposing similar ideas that are mutually reinforcing, that is, functional theories like neuroeconomics and cognitive linguistics.
This also means I&rsquo;m building off theories developed by others, trying to see how the could be integrated in a shared framework.
I am not confident enough to say this is any kind of revolutionary theory. I think there are enough ideas that
suggest there&rsquo;s a coheasive theory here that I want to develop as best I can.
That&rsquo;s my ultimate goal with this project, to construct a theory out of these principles and ideas that I think
work together. How useful such a theory will be, time will tell. But the theory as an exercise in thinking
about integrating ideas across fields can stand as its own instructive structure in any event, as meek an ambition
as that might sound.</p>

<p><strong>II. Introducing Neuroeconomics</strong></p>

<p>The neuroeconomics base I want to build from has been developed by Paul Glimcher in his book <em>Foundations of Neuroeconomic Analysis</em>.
So the start of this section will largely be a summary of that work, with me offering observations about the parts which should be useful for
forming the basis of NEATL theory, i.e., serving as the foundations for the higher levels.</p>

<p>As mentioned above, at the base of the theory is activity in cortical maps in the line of transit from afferent (sensory processing) to efferent (action processing) pathways within discrete(ish)
modalities of perception and action, those maps whose activity function as the triggering gatekeepers to action-signals running down efferent pathways to kinematic systems
to ultimately direct action. Following motion-signals running up efferent pathways, one eventually reaches threshold points where action-directing signals originate.
The cortical maps serving as gatekeepers to those last-node pathways are the ones we&rsquo;re interested in here.
 Functionally these are decisionmaking mechanisms, neural mechanisms which create a &ldquo;decision making space&rdquo;, a space one can model geometricly more or less concretely to abstractly,
and act within that space to evaluate the &ldquo;value&rdquo; of decision possibilities according to various considerations, and select a winning
course which is triggered into action and followed-up on. Also included are associated mechanisms, such as coordinated activity across multiple maps, and the set of mechanisms
 registering the activity as a decision to other systems, e.g., the feeling of volition and self-attribution constructed in parallel with the action outputs of the decisions.</p>

<p>Neuroeconomics &ndash; in my understanding and as an oversimplified starting point to unpack &ndash; is a theory about modeling human
decisions from the perspective of the decision-making cortical maps at the ground level of evaluating, selecting, triggering, &amp; following-up on
discrete actions by action modality.</p>

<p>A major part of the theory is developing the models of how these mechanisms operate. But the theory goes further by trying to connect
the operations as the causal, explanatory bases for higher levels of description of human action.
That&rsquo;s why the next theory to add is action theory, the construction of complex, coordinated chains of actions across time, which is the topic of the next chapter.</p>

<p>Before turning to the mechanics of the cortical maps, I want to do two things, (1) sacrifice or demystify some sacred cows so that it&rsquo;s easier to imagine a framework without them,
and (2) take a bird&rsquo;s eye view of the entire model (in Glimcher&rsquo;s framing).</p>

<p>(1) Demystifying Sacrificing some Sacred Cows</p>

<p>First, it&rsquo;s useful to clear the road of the detris of past frameworks and take the attitude that nothing is sacred.
At the center of any theory should, above all, be established empirical findings. After that we have principles of
theory-building that include self-consistency and base principles that we can observe appearing over and over with some confidence.</p>

<p>For some old sacred cows, we want to completely debunk them as wholly inconsistent with our framework and not hesitate in
tossing them in the trash heap of outdated theory. However, even in doing this, it matters <em>why</em> the old theories are inconsistent,
and explaining the inconsistencies can go a long way to capturing what NEATL is in the positive sense.<br />
Some parts of old theories we need to keep for our framework, not because of tradition, but because they founded on
well established empirical findings and have a natural place in our theory.</p>

<p>The following is the summary version. (I&rsquo;ve written up a <ul>longer version</ul> walking through these and others.)</p>

<p><strong>+ Freud et al</strong>. As Karl Popper noted, Freudian psychology is the textbook case of non-falsifiable.
It&rsquo;s a top-down model that doesn&rsquo;t explain how anything is caused, but it reifies every conceivable human activity into
high level structures that basically repackage them into narrative forms people feel like they can make sense of.
Long story short, we want a bottom-up explanatory model where behavior is explained in terms of structural features of neurophysiology.
Higher level psychology does have something to add as explained in the next section, not as an explanatory model, but more as a roadmap to function.</p>

<p><strong>+ Sherrington / Hebb</strong>. Sherrington&rsquo;s model of the nervous system is upward afferent pathways meet downward efferent pathways, and in
the middle they simply conduct stimulus to response. Hebb&rsquo;s model of changes in neural weighting gave support for a reinforcement-learning model,
where the outcomes re-calibrate the conduction model so that stims activate the proper responses.
<strong>+ Pavlov / Skinner / Watson </strong>. The behaviorists basically turned the stim-response conduction model suggested by Sherrington&rsquo;s neuron model
into a psychology, where reinforcement learning equates stimulus to proper responses to maximize utility.</p>

<p><strong>+ Frege / Carnap / Predicate Calculus</strong>. Neuroeconomics and NEATL Theory are subsymbolic levels of description of the construction of meaning.
The treatment of semantics in the line through Frege and Carnap is based in formal functions and set theory.</p>

<p><strong>+ Sassure </strong>. Sassure&rsquo;s framework of signifier-signified is another type of blackbox function that doesn&rsquo;t explain anything.
The relationship between words and concepts/referants is part of a deeper system of the action-production with perceptual-recognition, and orientations
of action the agent takes towards the world. It&rsquo;s better to toss out over-simplifying formulas like Sassure linguistics and look at
the operation of these systems themselves to explain linguistic features. A lot of operations are happening beyond the boundaries of
the signifying elements and the signified elements, so it&rsquo;s better to toss out the entire framework that both leaves them out and focuses on the wrong elements.</p>

<p><strong>+ Chomsky</strong>. Chomsky argued that the language system is a self-contained module whose primary function is to
operate an innate (gentically input) grammar, which arbitrary langauges can flesh out.
Cognitive linguistics frames language construction and operation within the framework of action-production, not a separate system at all.
There&rsquo;s no inherent linguistic grammar (although there&rsquo;s some structure to all action-production that is grammar-like); no formal separation of linguistic action from other types of action;
no separation of grammar and pragmatics. The starting point for cognitive ingiustics is not the search for structures of innate grammar
but a story about how the structure of language is bootstrapped in language learning during child development, exactly the
starting point which Chomsky denies.</p>

<p><strong>+ Piaget</strong>
<strong>+ Vygotsky </strong>
Speaking of child development, I&rsquo;ll have to come back to the two godfather&rsquo;s of child development theory.</p>

<p><strong>+ Keohane [&hellip;] / behavioral economics </strong>. The phenomena of cognitive biases are well established findings that will need to be a part of any model.
The issue with Keohane&rsquo;s treatment of cognitive bias theory is that they imply these biases are cheap hacks wedged into an otherwise rational system.
Neuroeconomics provides a framework in which evolution has designed a coherent and self-consistent system operating based on a set of structural features and principles,
out of which the &ldquo;biases&rdquo; emerge as normal design features. They are the exact opposite of hacks; they represent the very core design principles of cognition on planet Earth.</p>

<p><strong>+ Fodor&rsquo;s Massive Modality </strong>. The current trend in neurophysiology work is a much more networked model with upstream, downstream, and lateral-stream
pathways sharing work among parallel structures, especially for what we call conscious and volitional behavior (the more automatic, the more self-contained operations
can be).</p>

<p><strong>+ Baars&rsquo; Global Workspace</strong>. Baars&rsquo; model has been influential in thinking about conscious and volitional operations in operational terms, but
both major elements, the &ldquo;global&rdquo; and the &ldquo;workspace&rdquo; parts, should not be taken so literally as to put restrictions on the types of mechanisms mediating
consciousness and volition, which may be quite fragmented and local (or glocal).</p>

<p>I have a few heroes, as will be obvious.
Maars, Glimcher, Morsella, Bogdan, Langacker &amp; the CogLinguists, Jackindoff&hellip;
We should be wary of mythologizing them as well, and for good measure I can add parts I find missing from them.
<strong>+ Glimcher.</strong> Focuses on functional features of groundlevel structures. The biggest piece I want added to his framwork is action theory. At some point it&rsquo;ll have to add
  action scripts. It&rsquo;s the difference between hot decision making (based on &ldquo;gut feelings&rdquo;) and cold decision making (based on &ldquo;deliberation&rdquo;), which in some cases work
  oppositely, cf. Glimcher&rsquo;s own discussion of risk factoring.
<strong>+ Bogdan.</strong> Bogdan to me provides a credible map from action &amp; signaling theory to bootstrap core features of language, predication and drawing meaning out of sentence structure.
  The shortcoming is, it&rsquo;s not connected to cognitive structures at all, and the empirical grounding is slim to non-existent. Once those parts are added, it becomes
  the basis for a very powerful theory.
<strong>+ Morsella</strong>. Morsella focuses on the &ldquo;consciousness&rdquo; perceptual side of the action-system coin, but shortchanging the actual action side.
  In that way, I think of Glimcher and Morsella as two sides of that coin, and I think about combining their frameworks into one framework for conscious volitional action
  system.
<strong>+ Langacker, et al</strong>. A joke you&rsquo;ll see sometimes is that, whatever cognitive linguistics is, it&rsquo;s not cognitive. Like I mentioned with Bogdan, the classic
  frameworks for cognitive linguistics did not try to build their systems in terms of actual cognitive mechanisms in the brain, or hardly anything coming out of the
  cognitive science literature. This is changing a little, but even the articles that try to build cogLing features out of cognive structures are still quite fragmented
  and have the scent of arbitrariness. If we&rsquo;re building a unified framework out of neuroeconmics-plus, this is the framework that one would want construct
  cognitive linguistics, probably not the form it&rsquo;s been developed to date, but a reconstructed version that takes some of its principles and insights and
  reconstructs them in the framework of NEATL Theory.</p>

<p>Combining these people&rsquo;s work and filling their mutual gaps is part of what I see as the purpose of this project.
The end goal, though, is to think about a grand unified theory of volitional action, and through it the major human practices that operate
through volitional action, language, self-actualization, social and cultural practices of every stripe: ethical, political, religious, vocational, recreational, economic, etc, practices.</p>

<p>(2) Bird&rsquo;s Eye view of Neuroeconomics</p>

<p>I want to take a short bird&rsquo;s eye view of neuroeconomics.</p>

<p>The punchline of the theory is a set of relationships between three levels of analysis, microeconomics, psychology, and neuroscience.</p>

<p>[Three Layer Diagram]</p>

<p>[&hellip;]</p>

<p>One could understand the gist of the theory with this diagram of the relationships among the three levels. The relationship between levels is not best framed as a reduction, but as lower levels providing explanatory power (the top-level theories operate as they do because of the lower level operations; in this way Glimcher calls neuroeconomics a &quot;because&quot; theory) while each level also provides constraints on the other levels. [example]
It is worth spending a moment with the idea of a &quot;because&quot; theory, versus an &quot;as if&quot; theory, as this also plays heavily in linguistics. […] Each level also provides a type of guidance to the other levels. While the lower neuroscience level offers explanatory power and limits what the higher level theory can say, the higher level theory provides the theoretical structure through which one can understand the structure of lower level functions. It provides the higher level forest view to make sense of what the activity of the lower level trees is adding up to, and what to look for. This is keeping with the functional neuroscience approach.
The other reason Glimcher’s model is instructive is that it presents a method in which one first identifies the major theoretical concepts or objects, and then understands the relationships among levels as explicitly linking objects at each level.</p>

<p>Now I will introduce the major pieces of the theory. I will introduce it in layers of complexity.</p>

<p><strong>1. Volitional Cortical Maps</strong></p>

<p>This chapter is going to start with the triggering of individual discrete motions, or as individual and discrete as we can pare the activity on the maps
down to. The triggers for such actions are close to the atomic level of volition, so it&rsquo;s worth spending time with them.
One of the principles that neuroeconomis suggests is that more complex action is compositional, constructed by the coordination of these pre-arranged atoms of action.
This is one way it addresses the classic chunking problem; the problem of defining the most basic units of perception and action and how they combine and coordinate.</p>

<p>[Cross Link to &ldquo;Cortical maps in development&rdquo; page]</p>

<p>To fill that out a bit more, just as &ldquo;gatekeeper&rdquo; mechanisms on the maps for the final signals down efferent pathways define the atoms of action, both volitional and reflexive,
so the units of processing by evaluation mechanisms on structures on these maps which coordinate action scenarios with perceptual elements packaged on the maps
for that purpose define the atoms ofperceptual elements, and in the case of executive maps coordinating action across multiple modalities, something we&rsquo;ll look at later,
the atoms of consciousness qua attention. There are mutliple layers being processed at multiple levels of scale in parallel, though, so it&rsquo;s not designed to
make individual processing mechanics appear recognizable as such.
And because these mechanisms are complex and composite, however, the term &ldquo;atom&rdquo; shouldn&rsquo;t be taken too literally.
It&rsquo;s atomic
from the mechanical perspective of how higher levels of description are constructed and packaged from pieces, but not from the perspective of their own construction; although even here mechanisms such as the [&hellip;MaxArg] are designed to function relatively discretely.</p>

<p>That simple picture is going to be complicated by action modalities that involve sophisticated, composite, coordinated motions as part of the &ldquo;same&rdquo; action, such as
involved with speech (think of the coordination of diaphram, larnyx, toungue, jaw, face, lips, etc., involved in the anunciation of a single phoneme), or with
even simple actions like taking a step, waving one&rsquo;s hand, or simply turning in place. This, again, will be the subject of the next chapter.
This chapter isn&rsquo;t covering &ldquo;single&rdquo; actions like that. It&rsquo;s covering individual, discrete triggers on a cortical map.</p>

<p>The principle is that these discrete triggers are the building blocks that executive mechanisms can package together into more or less arbitrarily packaged
(within limits) units of action, which packages can be triggered as such, as phonemes or set gestures.</p>

<p>If these packages are the &ldquo;atoms&rdquo; of action, selected and triggered as packages, then the decisionmaking map triggers are like the quarks that
are packaged to make them, although sometimes it happens that a single trigger mechanism can serve as its own package. (The package-ability of
action units actually varies by modality as intimated above, saccades package differently than utterances, or leg or arm stretches, etc.)</p>

<p>All of this is rather abstract, so it&rsquo;s good to look at a specific example.
Glimcher&rsquo;s work focuses on decision-making maps for eye saccades.
As far as action modalities go, it is among the most researched, documented, and self-contained.
A single eye saccade can be matched to a single trigger within a single cortical map, with the activity giving the eye muscles
all the information they need to properly move.</p>

<p><strong>2. The Mechanics of Eye Saccades</strong></p>

<p>Glimcher&rsquo;s work focuses on the cortical maps controlling the evaluation, selection, and triggering of eye saccades,
 most substantively by his primate studies, actually measuring activity of individual neurons directly (invasively) and in real-time as
  the primate conducted saccade-based tests, basically simple game-theory economic games like the work-shirk game.
Glimcher&rsquo;s model model system got more hedged and more complicated over time, so even it isn&rsquo;t the perfectly crystallized
 volition platform one would design top-down. (And of course other systems only add to complexity from there.)
 Biology is typically like that. It spreads function out across multiple maps, with redundancy and unclear boundaries and attribution,
 since the maps are heavily interconnected so activity on one induces corresponding activity in the others.
 We shouldn&rsquo;t want to be too quick to dismiss the relevance of the redundancy and ambiguity in function though.</p>

<p>The areas and activity Glimcher looks at are the lateral interparietal nucleus (LIP), [others] as they function in saccade-based economic games.</p>

<p>That said, there is activity which can be viewed as having the function of evaulating the value of possible courses of action,
and mechanisms associated with them that have clear attributability in selecting the most valued course of action
(factoring it with a few other contextal elements, including native randomizing nudges).</p>

<p>It&rsquo;s these &ldquo;evaluative&rdquo; structures and &ldquo;selection&rdquo; mechanisms which Glimcher focuses on. Even if activity is spread across maps, one can hone in on selection mechanisms
as the key mechanism in decisionmaking and volition.
The complexity comes in as layers of activity set up the evaluative platform on which selection occurs.
And one may find multiple layers of inputs into the evaluation and selection activity, just as they send out signals acting on other maps.
But having a single discrete selection mechanism focuses us to the key location for decisionmaking. It&rsquo;s like the hub which
focuses all the messy evaluative activity, factoring decisions across countless considerations, pre- and post-decision, to a small set of decisionmaking platforms
where final decisions are triggered and sent down as action and other mechanisms, such as conscious representation of the decision post-event.</p>

<p>I want to break-down this whole system into three parts, pre-decision evaluation, decision trigger, and post-decision action and representation,
although I am open that these parts may not cleanly align pre-, at, and post-event and may cross boundaries or be fuzzily boundried without clear lines viz. the event.
I am more interested in function and the mechanics of dependence.</p>

<p>Other systems. Arm/Hand and object handling, Transversing a Region (walking, etc),
Perceptual systems. Morsella on Olfactory sensitivity to action,</p>

<ol>
<li>Evaluation &amp; Decision-making Space<br /></li>
</ol>

<p>In the vision system, there is a sequence of cortical maps representing data about the visual field.
On the afferent end of the trail, activity would represent objects in the visual field. On the efferent
end of the trail, activity would represent a saccadic movement of the eye to bring that area to the center of the field.</p>

<p>Glimcher&rsquo;s narrative about activity on LIP is that it is neither afferent or efferent, neither
representing information about objects in the visual field (since there can be activity in areas where there aren&rsquo;t
objects in vision) nor about movements of the eye (since there can be activity in areas where there isn&rsquo;t motion).
In a series of clever experiments, he concluded that the activity represented roughly the reletive expected utility (which he renamed
&ldquo;subjective value&rdquo; to distinguish it from the mathematical concept in economics).</p>

<p>Glimcher&rsquo;s most useful experiment for understanding the activity was setting up a work/shirk game well studied
in game theory, with the agent being [macquae monkeys with invasive detectors registering their LIP area).
Each round of the game, the agent can choose to work and get a regular small payoff, or
one can choose to shirk (take the day off) and take a risk that the boss is not in the office and receive
a much bigger payoff (still getting paid for the day &amp; the benefits of the day off),
otherwise the boss comes in and the agent receives zero payoff (not getting paid that day).</p>

<p>He set up a screen with a green button (for work) on the lefthand side and red button (for shirk) on the righthand side.
At the start, the agent is instructed to look at the center for 10 seconds, then look at one of the buttons for 10
seconds, after which the payoff comes in the form of a juice shot, either small sized, large sized, or nothing, dependeing on the case.</p>

<p>If one sets up the situation so the shirk move gave the bigger payoff randomly in <sup>1</sup>&frasl;<sub>3</sub> of cases, then the Nash equilibrium
strategy would be to choose the shirk move randomly with a <sup>1</sup>&frasl;<sub>3</sub> probability. Any more than that and one would only be
falling below the payoff of choosing work. The behavior of the [monkey], like humans, quickly converged with the
Nash equilibrium strategy when repeating the game many times. (If one changed the probability of the shirk payoff,
the equilibrium trategy would change and converge over a number of trials.)</p>

<p>The punchline was that the activity of LIP represented the region of each button in correspondence
with the relative expected utility of each option.
First, the areas would light up at the start, when the agent was instructed to look only at the center.
So the activity did not represent instructions to look at either area.
And the button images could actually be removed, keeping the rules of the game (the agent is instructed
to look at the area where it was), and the areas still lit up. So the activity did not represent
 visual objects at those areas.</p>

<p>The work area would have a consistent level of activity.
The shirk area&rsquo;s level of activity varied over rounds of the game.
When the game was a <sup>1</sup>&frasl;<sub>3</sub> payoff scenario, it would light up with a same or greater level
of activity on <sup>1</sup>&frasl;<sub>3</sub> of the rounds, after which the activity would fall below the work level.
There was a stochiatic randomness added to the activity which wobbled the signal and its location
proportional to the size, a mechanism I&rsquo;ll look at in more detail later. [&hellip;]</p>

<ol>
<li>Selection / Decision-Making, Triggers, and their complications</li>
</ol>

<p>LIP had a selection mechanism for triggering an action whose activity passes a threshold of priming,
and sending it down efferent pathways as instructions for movement.
Part of the selection mechanism is a corresponding mechanism which zeroed out the other regions
activity to negate the potential competing decisions to trigger, at least over the course of enacting the triggered selection.</p>

<ol>
<li>Action &amp; Conscious Representation
Aside from a decision sending down instructions to the motor cortex and other systems to plot motion,
there should also be signals to induce a conscious representation of the decision, post-event, as a volitional trigger for attribution purposes,
which nevertheless is properly packaged as part of the same discrete event; since by this point the command is locked in the efferent pathway down to action.
(I think there are dual- or multiple-representation packages as well, the volitional trigger tied to the pre-motion muscle contraction-anticipation tied to the actual muscle
contractions. With something like phonemes, the representation would include the acoustic-packaged-structure, and an analog of volition, anticipation, and muscle contraction tied to it, etc.)
[contra the typical commentary behind the thumb studies which claims decisions aren&rsquo;t free if conscous representation comes later. We&rsquo;ll have to come back to this argument later].</li>
</ol>

<p>[&hellip;]</p>

<ol>
<li>Computing Subjective Value</li>
</ol>

<p><strong>2. Elements of Neuroeconomics</strong></p>

<p>We can give functional interpretations of these mechanisms, and we can also reconstruct decision theory concepts through these mechanics.
With that in mind, I want to consider a number of decisionmaking concepts.</p>

<p><strong>Option Selection. </strong></p>

<p><strong>&ldquo;Evaluation&rdquo;, Comparing relative activity / subjective value.</strong></p>

<p><strong>Payoff &amp; Satisfaction.</strong></p>

<p><strong>&ldquo;Subjective Value&rdquo;</strong></p>

<p><strong>Baselining.</strong> Stevens Power Law &amp; the cortial decisionmaking map version.</p>

<p>One way to frame this model is as an expression of the massive modularity thesis (Fodor) via network modality (Morsella).
[…]</p>

<p>At this point, it’s time to walk through the theory objects from the top level formal perspective, describing how the lower level objects explain their operation.
Subjective Values, and Relative Subjective Values. Neuroeconomics distinguishes utility from subjective value. In classic economics, utility was understood as a kind of logical construct loosely representing the value of an object for purposes of choosing that object viz. other objects. In modern economics, this representation gets flipped around, where instead of assuming utility defines choice, choice outlines a utility curve.
“GARP proved that any subject who shows no circularity in her choices behaves exactly as if she were really trying to maximize a weakly monotonic utility function.”  [“A monotonic utility function in this sense is one that goes up as the quantity goes up. It is a utility function that captures the idea ‘more is better.’”] [Weakly monotonic means the function either goes up or is flat, since as one gains more of something (apples), there comes a point where more is not actually better and may be worse. ] GARP does not prove a literal utility curve exists in the mind so much as prove that agents acting non-circularly in their choices behave as if they were following the curve.
Subjective Value (SV) is something much more concrete. It is a real number from 0-1000 representing neural action potentials per second of a neuron or neuron set representing some choice on a decisionmaking platform. SV has a very direct relationship to choice. There are two routes through which neuron activity trigger action or a choice: (1) when the SV of a represented choice crosses a threshold value triggering the represented action or (2) by the SV outranking other proposed choices represented by the SV of other neuron sets with a “winner take all” mechanism (equivalent to a ArgMax mechanism in economics) which triggers the winning action and extinguishes the SV activity of the other proposals, effectively selecting the winning choice for action. Both of these routes are functions of SV strength. As humans make choices according to SV activity, something akin to a monotonic utility curve may emerge; however, using different terms emphasizes that SV and utility are understood and measured by different methods, and they are not necessarily the same. SV is of course the more all-encompassing value in that, as effectively the sine non qua of choice, by definition [ex hypothesi] it is always coterminous with choice. In situations where a classic utility curve and SV differ, it will be SV that will more perfectly represent human choice. Classic economic theory would actually define deviations from a utility curve, or violations of WARP or GARP as deviations from rational behavior, in some sense “wrong” from a normative perspective; and from a descriptive perspective it would simply be without resources to explain the deviation, except as either a ‘just so’  ad hoc explanation constructed just to explain the deviation in terms of utility (which has no empirical ground further than it occurred to and made sense to the author).
SV of course does not allow for deviations or “wrong” choices, because its activity simply is, or is the key part of, the mechanism of choice. It is a fully descriptive theory which, at this primary level of explanation at least, does not offer any normative considerations whether a choice is good or bad for an agent in the short or long run, although it may have considerations to contribute on deeper reflection (we will consider that issue later).
Can we call the method of measuring SV a theory of choice?
One issue, from the perspective of prediction and explanation, is that measuring the SV of neuron sets by itself does not give us an equation of or guidance towards what the SV level will be in various cases. We need to know the information going into the neuron sets which actually lead it to have the SV level it has, or even better the structure of that process. A complete account of that structure would be more properly a theory of SV.
Glimcher’s Foundations offers a number of pieces to this structure, our understanding of which is already good enough to ensure that they will be essential elements however the theory develops.
Many elements fall out of psychophysics.</p>

<p><strong>Stevens Power Law:</strong> power-law fall-off curve of subjective percept intensity of modality (brightness, sweetness, etc.)/neural activity/SV intensity ([Weber-Fechner Law], p. 90),
Transducer biophysics: Relativization of signal</p>

<p><strong>Stociasticity</strong>, two types:
(1) Random Utility Model/Poisson Process: mean &amp; variance increase together; stociasticity/probability increases as intensity increases <a href="2">“As the average inter-spike interval of a Poisson process neuron shrinks, so does its variance, and at exactly the same rate.” (p. 207). “To put all of this more compactly, we can take the ratio of standard deviation to mean, a measure called the “coefficient of variance” (CV). For a Poisson process this number is 1.” (p. 208)</a> Trembling Hand (Selten)/Stochastic Transfer Function. Stochiasticity inherited by transfer from input-systems. P. 216 ff.
…
This provides a better idea of how SV operates in terms of its own mechanics and in terms of its contribution to human choice.
Can we characterize SV in phenomenological terms?
In raising that kind of question, before addressing it head-on, I think it’s important to address a number of caveats to the concept of SV to avoid misunderstanding it.
As will become evident in future chapters, the way we articulate value, or our perceptions of value, in natural language involves a translation process into language, which means it does not exactly represent how SV actually operates.
A step before this, the activity of SV involved in actual decisonmaking also involves a translation into our conscious feeling of “desire” (we will need to be more precise about how to characterize this feeling and its relationship to SV).
Thus it would be prudent from the start to distinguish SV from the way we describe our experience of value in reflecting on some thing in the context of a choice, both in terms of our actual feeling/experience (including perhaps our short term working memory of the feeling or other derivative forms which may be the more relevant elements to our reports on the feeling), and our translation of that experience or possible derivative forms into language. This type of distinction is a common theme throughout this entire work; we will want to make it essentially for every category of experience we have a tradition of explaining in language. (This is the groundwork for a theory of folk psychology.) It will become a critical piece in later chapters as the relationship between SV calls and language utterances about those calls, and the mechanisms that mediate that relationship, will be a foundational element to our theory of language.
These observations raise caveats to the idea that SV represents something that we can fairly call “subjective” (something we internally feel) and “value” (the internally felt pull we have towards the appeal of a thing, within its modality, in the context of a choice to obtain the payoff it offers in that modality, a hit of sweetness or savoryness or the like.).</p>

<p>For now, we should think about SV only in the mechanical terms of the mechanism by which choice is realized within the platform(s) for action selection for a given action modality, and bracket for now any concept of an internal feel of “subjective pull” associated with the SV towards that choice/action, which we will return to later in the context of [Action Theory and later the Language Acquisition Bootstrap, where that concept will play a leading role.]</p>

<p>[Re the old free will problem: could one have acted differently?
Not in the &ldquo;same&rdquo; world, but in an &ldquo;indistinguisable&rdquo; world. Re: stochiacity. Entropy is the number of physical states a system could be
 in physically indistinguishably. The two stociastic systems have a measure of inherit indeterminacy in the result, in two realities indistinguishable in the entropy sense.</p>

<p>………..
[There’s an important space between transducer biophysics to SV. That is a set of mechanisms which connect an expected SVPO payoff by conducting a “move”, within the modality of an action system, to the SVDC strength of the move within the decisonmaking platform of that action system.
There are a number of necessary elements called for here.
One is realizing or recognizing the action as a discrete “move” within the frame of the situation, itself within the domain of the relevant action modality or network of modalities (object manipulation, transportation, etc.)<br />
One might think of a frame heuristically as the “game” or “situation” the agent understands itself within, and within which the action makes sense viz. making progress or some “move” within that frame, that is, within the logic of that frame’s normative structure (heuristically, the rules &amp; norms of the game).
That heuristic is serviceable at this early point, but not very accurate. First, we are speaking pre-linguistic action, the instinctive (but still volitional) action of animals and ourselves in certain situations (D’Amasio’s first level consciousness). So there is no explicit recognition a game one finds oneself in, much less a move within a game. What there is is an orientation of the agent to its environment and various impulses to take action within that environment as oriented-towards, which impulses carry (or have the potential to) the normative structure of the domain and frame within their received or conscious character.
Such an [instinctive] recognition or orientation of the situation is quite diminished from what we would want to call a game or action-situation. It is an environment within which action impulses are received, which impulses have a normative structure within the situation, or rather, the construction of the situation is constructed by the normative structure of the action-impulses themselves. Consistent with our heterarchy principle, we might expect a top-down and bottom-up interplay, as the action-impulses in part construct a situation as recognition of features of a situation in part construct action impulses, and the entire system dynamically develops.
The value of the payoff, as computed by sense transducers, is not the same thing as the strength of the decision-call to achieve the payoff, although there is undoubtably a close association between the two which leads the latter to often conform to the former.
The next is realizing or recognizing the move to have some expected payoff within the frame, or within the normative structure of the frame. (A note on probability: SV does not represent probability per se. It is a value the strength of which is modulated by recent experience of payoffs for the same “move” within the same “game”.)
Glimcher’s cases are rather simple in that a single discrete move (a saccade) is matched with a discrete payoff with some variable probability. The translation from the payoff transducement (as a function by recent experience of success) to SV strength is rather unmediated by other considerations. But what if the payoff is mediated by other elements, such as a sequence of actions before the payoff is achieved. This line of questioning will brings us to the next section on Action Theory.
Before we cover full-blown complex action, we need to address the roles of what we will call (referencing the wider psychology literature) “script”, “frame”, and “domain” even for discrete single actions or moves. The mechanical version developed here is a diminished version from the way these concepts are described in the psychology literature, however.</p>

<p>Neural Activity “Move” Construction on Decisionmaking/Action Platforms
+   Status, Change, and SV
There are certain tasks the mechanisms creating activity on action decisionmaking platforms have to accomplish, with access to certain information.
There has to be a construction of the strength of an expected SV payoff.
We cannot assume a mechanism that receives the strength by fiat.
[transducer]
The logical or normative structure of a “game.”
Glimcher spoke quite a bit about the construction of understanding of the normative structure of a “game.”
[Memory, Concave Power rule with distance back in time, adds up to a rough rule slowly converging to Nash equilibrium.]
This kind of mechanism approaches a dynamic Nash equilibrium sufficiently enough in practice to allow agents to choose action strategies to receive a payoff, with instinctive behavior, close enough to the equilibrium to maximize its payoff.</p>

<p>……………………………………………………………………
+   Preferences. The added marginal strength of a perception X, as X increases, falls off on a power-law curve (such as X^.6 curve). Preference for X, by extension, also falls off on a similar curve. The source of this is the mechanics of transduction, the process where the raw physical signals of X (the number of photos, the number of sugar molecules) is converted into a neural signal (action potentials per second). As X increases, at higher amounts it takes exponentially greater amounts of X to make equivalent increases in one’s perception of it, and by extension one’s preference of it.</p>

<ul>
<li><p>[Reservation based Search]</p></li>

<li><p>“Reference”-Based Biases (status quo, entitlement, etc.). Additions and deletions of X are treated differently in terms of the change in strength of the preference (subjective utility), and this change is sensitive to a reference point, a salient amount of X one has in mind and against which one judges the relative difference of a new amount of X. The basic finding is that additions to the baseline are diminished (they feel smaller gains than they actually are) and deletions against the baseline are augmented (they feel like greater losses than they actually are), with the diminishments and augmentations feeling greatest closest to the baseline. (Additions and deletions at much greater levels of scale above or below lose the effect.)</p></li>

<li><p>Stochasticity. There is a normal curve-like randomness built into decision-making, where expected behavior falls off from a SV utility maximizing move, the curve of which grows in proportion to the scale of the SV utility, called […]. Glimcher introduces two types, one is</p></li>

<li><p>[RUM]</p></li>

<li><p>Discounting</p></li>

<li><p>ArgMax/Choice</p></li>

<li><p>Subjective Utility</p></li>

<li><p>[Independence Axiom]</p></li>

<li><p>Value/Learning</p></li>

<li><p>Dopamine</p></li>
</ul>

<p>……………………………………………………………………</p>

<p><strong>Morsella&rsquo;s Passive Frame Theory</strong></p>

<p>Ezikiel Morsella&rsquo;s Passive Frame Theory (PFT) appears to be a close fit with Glimcher&rsquo;s neuroeconomics.
It&rsquo;s close enough that I&rsquo;m going to use this section to try to explicitly link the two as
part of the same framework.</p>

<p>PFT is a theory about the link between consciousness and volitional behavior (i.e., the mechanisms instantiating it), or more to the point,
that consciousness is contentful representation in the service of volitional behavior.
In those terms, we can think about it as one category of mechanism of the volitional maps at the center of neuroeconomics.
Like above, it&rsquo;s probably easiest to walk through the claims and give commentary about how it fits with
the larger neuroeconomic framework as we go.</p>

<p>Features of PFT:</p>

<ul>
<li><p>PRISM &amp; the Location of Consciousness
Consciousness is at the point of option representation on decision-making maps, not prior afferent or latter efferent paths.
PRISM =</p></li>

<li><p>The &ldquo;EASE&rdquo; Rule of Thumb. Elemental, Action-Based, Simple, Evolution-based.
This is</p></li>

<li><p>Low-Level
Consciousness is a low-level mechanic about low-level discrete decisions. It is not a higher-level property involving
language or self-awareness. Each conscious-content event does not know the contents of other events, or of its immediate
precessors or successors. (There is a mechanism which can recreate successors and envision successors, as new events,
which in natural langauge we call memory and imagination, respectively.)</p></li>

<li><p>The unconscious surrounding the conscious
To the extent PFT is a framework, in the architectural sense, it is about the structure of conscious and unconscious mechanics.
In my NEATL theory here, I&rsquo;m more interested in the global architecture.
From that perspective, PFT, in drawing the line between conscious and unconscious inputs and mechanics, is an insight into
the structure overall. One of the claims of PFT is that volitional/executive action is consciousness.
So the structure of consciousness surrounded by the support work of unconscious mechanisms is ostensibly a roadmap to the structure of
volitional action surrounded by the support work of automatic mechanisms.</p></li>
</ul>

<p>Now we need to be careful with the wording. In another entry I argue about the nature of free will.
What we call volitional action is not entirely consciousness. What is important is that, globally, it us &ldquo;under our control&rdquo;.
The role of consciousness is nuanced. It&rsquo;s important, but just as it contributes to the grounding that an executive agent,
a narrative of an executive agent, can justifiably claim ownership over the action.</p>

<ul>
<li>Consciousness is Perceptual
Perception is distinct from sensory in that it is geared towards action.</li>
</ul>

<p>There are some elements which Morsella&rsquo;s papers themselves (that I&rsquo;ve read) don&rsquo;t give much emphasis but that I want
to follow up on.</p>

<ul>
<li>Executive decision-making mechanisms
One of the foundations of PFT is that volitional decisions can take account of perceptual contents intigrated and
across modalities, the entire visual field, apprehended sounds, and imaginations of the same.
And these contents are available, functionally speaking (we&rsquo;ll get to structure in a bit), to global action
in the skeletomotor system, and (importantly) not at the level of discrete muscle pulls, but</li>
</ul>

<p>Volitional decisions link
, decisions of decisions.</p>

<p>To fill out how these mechanisms must function, we&rsquo;ll have to address Action Theory. That&rsquo;s the topic of the next chapter.
But it&rsquo;s important to note from early on that what we call volitional action and consciousness as it is available to
volitional action that it&rsquo;s manifested through the mechanism of global coordianted action.</p>

		
	</div>

	<footer class="entry-meta">

		<span class="tag-links">		
			
                <a href="/tags/neatl-theory/index.html" rel="tag">neatl theory</a>
            
                <a href="/tags/cognitive-linguistics/index.html" rel="tag">cognitive linguistics</a>
            
                <a href="/tags/cognitive-science/index.html" rel="tag">cognitive science</a>
            
		</span>
		
		
	</footer>
</article> 
			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

		<h1 class="entry-title"></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="/post/principles//index.html" rel="bookmark">
					<time class="entry-date" datetime="0001-01-01 00:00:00 &#43;0000 UTC">
						January 1
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		

<p>&ndash;
title: &ldquo;Proposed Principles of Human Being&rdquo;
date: 2017-08-25T15:25:01+09:00</p>

<h2 id="draft-true">draft: true</h2>

<p>I reserving this space to list some general principles and important points of my theory of human being, at various degrees of priority and inflexibility,
which I hope to amend over time as needed.</p>

<ul>
<li><p>At the root of the free will problem is the personal identity problem. Mechanisms integrating situations, norms, motivations, and volition
are mediating the will. The major issue from this is the extent to which it&rsquo;s fair to attribute these mechanisms to the self-expression
of an &ldquo;autobiographical self&rdquo;. This involves the integration of mechanisms of agency with the scripts running SDT in a coherent manner, among other things.</p></li>

<li><p>&ldquo;Free will&rdquo; is a function of explicit assertion of the narrative of self through self-determining action.</p></li>

<li><p>The explanatory order of systems that I currently think structures high level action is a neuroeconomic base of cortical action maps,
neo-Action Theory (executive heterarchical parallel action threads), signalling theory, social action, language bootstrapping, and
from there the script calculus of narrativology (from lower level concepts to high level SDT, institutions, and ways of life).
Each level builds on and works through the levels below it, with the neuroeconmic base always being the platform of action,
bootstrapped action scripts mediating meaning and narratives through them, and the penthouse being the brand of cognitive linguistics
shape by their mechanics.</p></li>

<li><p>The core of the approach is the mechanics of Action Theory and supporting systems (construction of situations and the self acting within them).</p></li>

<li><p>Contra-Chomsky, the core is not a logical innate structure of grammar. Our approach ends with a species of cognitive linguistics, where
linguistic action is a (specialized) form of volitional action generally.</p></li>

<li><p>Contra-Sherrington &amp; the behaviorists, the model of mind is not a conduction model linking afferent and efferent pathways.
The major players are the &ldquo;middle systems&rdquo; between them, systems which model and effectuate the functional structure of action in a situation,
such as volitional cortical maps, executive action planning, pre-frontal lobe action templates, etc.</p></li>

<li><p>Contra-Frege, et al, the base of meaning is not at the abstract symbolic level. We need a system which constructs the features of predication
at the intentional level. Bogdan gives us the roadmap, which we have to re-construct via plausible (bootstrapped) cognitive operations.</p></li>

<li><p>Contra-Sassure, we don&rsquo;t want to represent language in terms of [&hellip;] and [&hellip;].</p></li>

<li><p>Contra-Fodor, vanilla massive modularity isn&rsquo;t the major paradigm of cognitive organization, functionally or operationally.
The major paradigm is closer to a heterarchical semi-modular network model. (Cf. Morsella)</p></li>

<li><p>A sentence is a set of instructions to trained executive volition systems to construct a &ldquo;meaningful situation&rdquo;.
That&rsquo;s why the entire meaning cannot be contained &ldquo;inside&rdquo; the sentence proper (contra-compositionality thesis).
The formal content &amp; structure of the sentence are only the skeleton of indstructions; a signal-recognition system then fleshes it out with meaning
(through the volitional action systems).</p></li>

<li><p>Knowledge is encoded as tropes or more or less crystallized (pre-keyed) action strategies to negotiate knowledge-needing situations.
Understanding is a function of the sensity of inter-connections of these strategy maps, and the arrangement of &ldquo;keys&rdquo; guiding
the agent through the functional trope space to talk through an issue in a functionally &ldquo;successful&rdquo; way.</p></li>

<li><p>Key-map mechanisms proliferate via the mechanics of recognition, attention, priming, and action.</p></li>

<li><p>Consciousness is a low level and fragmented mechanism linking feature content (by sense modality) to executive action planning. (Morsella)</p></li>

<li><p>A fundamental feature of conscious content is relentless baselining. Light is bright according to its recent relative displacement, which is quickly
renormalized to a new baseline. Stevens Power Law, Khaneman). Sugar is sweeter when you&rsquo;re hungry. Losses hurt more than the same gains please, against
an &ldquo;entitlement&rdquo; or &ldquo;status quo&rdquo; baseline. Etc.</p></li>

<li><p>Our system is broadly a subsymbolic, neuroeconomic satisfaction system. Volitional systems prime heterarchical/parallel action threads, the triggers of which
(along with the change in world or situation state) cash in the priming as a subjective value payoff, which feedsback into future primings, and can get
crystallized into increasingly offline action tropes with repeated use.</p></li>

<li><p>Action priming is thickly parallel and heteararchical, in multiple respects. On the operational level: it&rsquo;s a negotiation of action priming and selection between ground level
bottom-up action systems (individual kinesthetic muscle groups) and top-down executive or higher level action systems (primed for coordinated sequences of actions, where
the earlier actions are already pre-programmed in integration with later actions, and other complexities, e.g., forking, parallelism, fragments, orphans, etc). Functionally, it&rsquo;s a negotation between
low level action plans (twisting one&rsquo;s wrist and flexing fingers to grasp an object), midlevel plans (pull the apple out of the bag to eat) and higher level plans
(eat lunch for today; have a productive routine at work so as to advance in my career). This includes a great amount of nuance and complexity we get from
sophsticated Action Theory, parallel and branching intentions, goal orphans, etc.</p></li>

<li><p>Words don&rsquo;t exist (as such). The mind doesn&rsquo;t encode a lexicon of words linking to meanings as such, like an internal dictionary.
In this theory, what we have are more like legal moves in a game that functionally advance the game-state in some way.
Words are more like strategies of action (to represent an object to a person) than symbols representing objects per se.
It&rsquo;s a subtle but important difference, particularly at the operational level.
This principle falls very naturally out of NEATL, where the langauge bootstrap is modeled specifically on crystallizing the rules and action strategies of a social game/ritual.</p></li>

<li><p>Notes on &ldquo;Words don&rsquo;t exist (as such)&rdquo;: Pulvermuller had the sensational discovery in the neurophysiology of language use (based I think on fMRI studies)
that word use does not have any special activity different from explicit memory knowledge generally.
To take this kind of finding seriously I think would entail a pretty revolutionary overhaul of what we think words, langauge, and knowledge actually are.
It reminds me of the quote in the Einstein biopic, when Einstein realizes with Lorenz&rsquo;s, et al, sensational finding that light doesn&rsquo;t change speed
in different moving reference frames that Lorenz doesn&rsquo;t get the bullet to the head to save Newton, Newton get&rsquo;s the bullet in the head to account for Lorenz.
Similar thing here; we have to re-do linguistics and epistemology to remodel words as action strategies to keep Pulvermuller&rsquo;s finding (and not explain the finding away to keep words).
John Hyman&rsquo;s book on action theory has a chapter to the effect that knowledge isn&rsquo;t a cognitive state but a capacity for action.
I think this theory might be in line with the NEATL model, but it requires more reflection to be sure.</p></li>
</ul>


		
	</div>

	<footer class="entry-meta">

		<span class="tag-links">		
			
		</span>
		
		
	</footer>
</article> 
			
				<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

		<h1 class="entry-title"></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="/post/sacredcows//index.html" rel="bookmark">
					<time class="entry-date" datetime="0001-01-01 00:00:00 &#43;0000 UTC">
						January 1
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p>First, it&rsquo;s useful to clear the road of the detris of past frameworks and take the attitude that nothing is sacred.
At the center of any theory should, above all, be established empirical findings. After that we have principles of
theory-building that include self-consistency and base principles that we can observe appearing over and over with some confidence.
The first means it&rsquo;s one coherent system where all the parts work together according to a consistent framework, not fragmented
systems for each type of function with no idea how they interrelate. (We can have multiple systems and multiple levels of description,
but we should have some framework for how those elements interrelate in a larger combined framework.)
By the second I&rsquo;m referring to some basic principles that have independently and repeatedly revealed themselves, or revealed
itself in a way that commands a lot of confidence. Morsella recommended four such principles, EASE (elemental, action-based, simple, and evolution-based).
I&rsquo;m going to offer a few more below, or take from other places like Glimcher&rsquo;s work, such as baselining &amp; Stevens Power Law, etc.
Another key area of principles is the level of description we&rsquo;re working at (the level of operation, cortical maps; a funcitonal perspective
based on the network of functions across maps, and not based on neurophysiology or structure with no inquiry into function, etc.)</p>

<p>Once we have something established, we should be sure that it has a solid place in the system, and isn&rsquo;t
arbitrarily dropped in other quarters just because it&rsquo;s not as visible.</p>

<p>So we want this framework to be self-consistent, based on empirical findings and its own principles, like the EASE and other principles like operational/functional.</p>

<p>For some old sacred cows, we want to completely debunk them as wholly inconsistent with our framework and not hesitate in
tossing them in the trash heap of outdated theory. However, even in doing this, it matters <em>why</em> the old theories are inconsistent,
and explaining the inconsistencies can go a long way to capturing what NEATL is in the positive sense.</p>

<p>Some parts of old theories we need to keep for our framework, not because of tradition, but because they&rsquo;re themselves founded on
well established empirical findings and have a natural place. But even here we want to demystify the authorative parts, so that we
can come in with the right attitude. Elements should stick around because they have a natural fit with a self-consistent framework,
not because of past authority. We should feel comfortable keeping what fits and tossing what doesn&rsquo;t. Even in demystifying, we shouldn&rsquo;t hestitate
to keep principles and findings which fit the model.</p>

<p><strong>+ Sherrington / Hebb</strong>
Classic behaviorism has to go. One of the foundtions of classic behaviorism is the Sherrington model of neural structure.
Sherrington introduced a conduction framework of afferent pathways of perception signals from senses up into the void, and efferent
pathways of action signals from the void down to muscles. In something like the neurophysiological equivalent of the Laffer Curve,
Sherrington&rsquo;s model suggested that at various points, the afferent pathways met the efferent pathways, and in between was a simple
conduction of glorified stimulus to glorified response. Hebb added the idea that neural pathways</p>

<p>This gave the image that the mind was a stim/response black box.</p>

<p><strong>+ Pavlov / Skinner / Watson </strong>
Pavlov, Skinner, and Watson constructed a conduction model of learning and behavior that was effectively operationalized Sherrington.</p>

<p><strong>+ Freud et al</strong></p>

<p>First, Freud is a top-down psychology of fiat, where high-level structures take the protagonist&rsquo;s role of construciting meaning and directing behavior,
E.g., a self-recognizing mechanism that takes actions to defend itself from emotional trauma or vulnerabilities.
Our model here is decidedly bottom-up. We describe in terms of neural structures that operate according to principles we construct out of observing their structure and behavior.
It&rsquo;s sub-symbolic, below the level of meaning and language; which is important, e.g., in that we don&rsquo;t have to assume some baseline of meaning and language already available, below
which we can&rsquo;t dig, which (1) puts an absolute limit on what mental behavior we can describe (only behavior mediated through meaning, but nothing else) and (2) is either groundless
(we can&rsquo;t talk about the mechanisms that construct meaning and language itself) or paradoxical &amp; self-exploding (to the extent one tries to explain the construction of meaning or language through
elements that already assume langauge and meaning).</p>

<p>We still want to keep a lot of classic psychology. Glimcher&rsquo;s model gives us a way to fit lower level structures (like decision-urging cortical maps) and higher-level structures
(like the construction of a narrative of self that acts, through executive action structures and the calculus of action scripts, on its own behalf, not only for self-preservation, but for recognition and self-actualizing.)
Basically, the higher-level structures give guidance of what the lower-level structures are acting towards, their function.</p>

<p>There are lots of good reasons why one would want to give priority to the bottom-up approach over the top-down one.
The major reason that first comes to my mind is that, in a bottom-up description, we&rsquo;re starting with structures that we
can immediately describe in terms of structure and function with concrete and discrete mechanisms.
They&rsquo;re structures designed out of evolution, constructed through genetics, and operate by the principles of neurophysiology, and you can connect all the dots quite
concretely.
For high-level structures, we have a lot of extra pieces we need to put in place before we can even start describing anything; we have to have years of child development
and language and cultural learning adding thousands of new elements on top of the vanilla system before our description has any traction over actual behavior.</p>

<p><strong>+ Frege / Carnap / Predicate Calculus</strong>
The formalization of semantics into glorified functions in the framework of set theory falls into the same top-down fiat trap that Freudian psychology does.
Our framework is subsymbolic.</p>

<p><strong>+ Sassure </strong>
One of Sassure&rsquo;s major principles is the framing of langauge in terms of a signifier/signified relationship. You can see right off it&rsquo;s
a conduction model, which we want to get away from.
It&rsquo;s at a symbolic level where it&rsquo;s operating as a conductive function between the word and concept or referant, when we want to describe at a
sub-symbolic level of the construction of meaning from non-meaningful elements.
What I don&rsquo;t trust about Sassure&rsquo;s approach is that it simply doesn&rsquo;t seem to describe the nuanced and much richer relationship between
word and concept one gets in cognitive psychology and cognitive linguistics. In cognitive linguistics, the meaning of a sentence involves
elements that are not within the formal structure of the sentence itself, which directly contradicts a few sacred cows, the signifier-signified
relationship, the hard separation of pragmatics from lexicogrammar analysis, and the compositional principle of meaning.</p>

<p><strong>+ Chomsky</strong>.
Chomsky argued that the language system is a self-contained module whose primary function is to
operate an innate (gentically input) grammar, which arbitrary langauges can flesh out. That put grammar at the center of language
cognition, and along the way segregated the logical structure of grammar construction from implementation and oust the action-oriented
side of language into other systems, or where it was necessary to contribute to meaning, he created a category he called &ldquo;pragmatics&rdquo; to keep it out of the language system proper.
Long story short, NEATL theory, like cognitive linguistics, has a framework of language construction and operation that&rsquo;s entirely integrated with action-production
system, and is not a separate system at all. There&rsquo;s no inherent grammar (the way Chomsky spoke of it; in our theory, there is a kind of functional structure of action which has grammar-like
features), no formal separation of linguistic action from other types of action, no separation of grammar and pragmatics. Most of all, cognitive linguistics
finds the search for structures of innate grammar as an awful way to investigate language, since it&rsquo;s very starting point is to ignore action systems
and how children bootstrap and learn grammar in child development (the starting points of cognitive linguistics).</p>

<p><strong>+ Piaget</strong>
<strong>+ Vygotsky </strong></p>

<p><strong>+ Keohane [&hellip;] / behavioral economics </strong>
The major issue with Keohane&rsquo;s cognitive bias theory, in the framework of neuroeconomics,
is that it treats cognitive mechanisms as if they were fragmented cheap hacks.
Neuroeconmics presents a self-consistent unified framework based on structure (action-based, evolution-based, principles),
that doesn&rsquo;t arbitrarily add or take away
So the already classic example is that the psychophysical mechanics of Steven&rsquo;s Power Law
provides the functional structure for the Baseline Cognitive Bias.</p>

<p>The [inverse power curve] built into the strucure of dopaminergic systems of valuation captures
the functional structure of the gambler&rsquo;s fallacy.</p>

<p>It is much better to understand these not as arbitrary fragmented biases, cheap hacks in the code, but as structural features
of a consistent system (built over billions of years of evolution, so the exact opposite of a cheap hack. Rather they&rsquo;re
foundational design pricniples behind the cognition of all life on planet earth since the Cambrian Explosion at the latest) that we
happen to notice give results
Granted, they are cheap in the operational terms of computational overhead to resolve everyday utiltiy-seeking issues, but not in terms of
structure or function. They&rsquo;re part of a well-designed coheret system that is acting exactly according to their core design principles.</p>

<p><strong>+ Fodor&rsquo;s Massive Modality  </strong></p>

<p>Current neurophysiology and cognitive science work describes the modalities of cognitive structure and function in a much more sophsticated
way than Fodor&rsquo;s relatively simple model. There are still mechanisms which address tasks relatively self-contained.
Morsella: the more automatic the response mechanism, the more self-contained its processing on inputs to last-path outputs.
But there is redundancy across maps; there are up-stream, down-stream, and lateral-stream pathways in densely networked maps and mechanisms,
with top-down and bottom-up processing.
This happens even with automatic functions, but it&rsquo;s particularly true for so-called &ldquo;volitional&rdquo; mechanism.</p>

<p><strong>+ Baars&rsquo; Global Workspace</strong>
Baars&rsquo; framework is still quite influential, but he used unfortuante, or at least potentially misleading terminology.</p>

<p>&ldquo;Global&rdquo; has the connotation that [&hellip;]. Our theory here suggests that contents are relatively discrete events which do not themselves
have access to other events or even their own predecessors or successors.</p>

<p>&ldquo;Workspace&rdquo; has the connotation that there are a few dominant mechanisms which integrate contents, as a platform on which recognition/attentional processing &amp; decision making
happens. It is better to read workspace more metaphorically. The mechanisms may be</p>


		
	</div>

	<footer class="entry-meta">

		<span class="tag-links">		
			
		</span>
		
		
	</footer>
</article> 
			
		
		</div>
	</div>
	<div id="secondary">

	

	<div id="primary-sidebar" class="primary-sidebar widget-area" role="complementary">
	
	<h1 class="site-description"><em>Mind | Society | Culture</em></h1>
	
		<script type="text/javascript">
    function site_search(obj) {
    	var host = window.location.host;
        obj.q.value = "site:" + host + " " + obj.ss_q.value;
    }
</script>

<aside id="search-3" class="widget widget_search">
	<form role="search" class="search-form" action="//www.google.com/search" method="get" onSubmit="site_search(this)">

	<input name="q" type="hidden" />
	    <label>
	        <span class="screen-reader-text">Search for:</span>
	        <input name="ss_q" type="text" placeholder="Search ..." class="search-field" />
	    </label>
	    <input type="submit" value="Search" class="search-submit" />
	</form>
</aside>

		<aside id="recent-posts-3" class="widget widget_recent_entries">

	
	<h1 class="widget-title">Recent Articles</h1>
		<ul>
			
			<li>
				<a href="/post/neatl1-theory//index.html">NEATL Theory 1: Introducing Neuroeconomics</a>
			</li>
			
			<li>
				<a href="/post/principles//index.html"></a>
			</li>
			
			<li>
				<a href="/post/sacredcows//index.html"></a>
			</li>
			
		</ul>
	
</aside>
		
		<aside id="categories-3" class="widget widget_categories">
	
	<h1 class="widget-title">Categories</h1>

	<ul>
		
		
		
		<li class="cat-item">
			<a href="/categories/theory/index.html">Theory</a>
		</li>

		

	</ul>

</aside>

		<aside id="categories-3" class="widget widget_tags">
	
	<h1 class="widget-title">Tags</h1>

	<ul>
		
		

	</ul>

</aside>
		
	</div>

</div>

</div>

		</div>

		<footer id="colophon" class="site-footer" role="contentinfo">

			<div class="site-info">
				<a href="http://gohugo.io">Powered by Hugo</a>
			</div>
		</footer>
	</div>

	<script type='text/javascript' src='/js/functions.js'></script>
</body>
</html>