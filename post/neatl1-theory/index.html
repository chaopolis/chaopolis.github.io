<!DOCTYPE html>

<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width">
	<title> &middot; Chaopolis</title>
	<link rel="profile" href="http://gmpg.org/xfn/11">
	<!--[if lt IE 9]>
	<script src="/js/html5.js"></script>
	<![endif]-->
    
    <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Chaopolis" />

    <link rel='stylesheet' id='twentyfourteen-lato-css'  href='//fonts.googleapis.com/css?family=Lato%3A300%2C400%2C700%2C900%2C300italic%2C400italic%2C700italic&#038;subset=latin%2Clatin-ext' type='text/css' media='all' />

    <link rel='stylesheet' id='genericons-css' href='/genericons/genericons.css' type='text/css' media='all' />
	<link rel='stylesheet' id='twentyfourteen-style-css' href='/css/style.css' type='text/css' media='all' />
	
	<script type='text/javascript' src='/js/jquery/jquery.js'></script>
	<script type='text/javascript' src='/js/jquery/jquery-migrate.min.js'></script>
	<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
</head>

<body class="home blog masthead-fixed list-view full-width grid">
<div id="page" class="hfeed site">
	<header id="masthead" class="site-header" role="banner">
		<div class="header-main">
			<h1 class="site-title"><a href="/index.html" rel="home">Chaopolis</a></h1>

			<div class="search-toggle">
				<a href="#search-container" class="screen-reader-text">Search</a>
			</div>

			<nav id="primary-navigation" class="site-navigation primary-navigation" role="navigation">
				<button class="menu-toggle">Primary Menu</button>
				<a class="screen-reader-text skip-link" href="#content">Skip to content</a>
				<div class="nav-menu">
					<ul>
						
					</ul>
				</div>
			</nav>
		</div>

		<div id="search-container" class="search-box-wrapper hide">
			<div class="search-box">
                <script type="text/javascript">
    function site_search(obj) {
    	var host = window.location.host;
        obj.q.value = "site:" + host + " " + obj.ss_q.value;
    }
</script>

<aside id="search-3" class="widget widget_search">
	<form role="search" class="search-form" action="//www.google.com/search" method="get" onSubmit="site_search(this)">

	<input name="q" type="hidden" />
	    <label>
	        <span class="screen-reader-text">Search for:</span>
	        <input name="ss_q" type="text" placeholder="Search ..." class="search-field" />
	    </label>
	    <input type="submit" value="Search" class="search-submit" />
	</form>
</aside>
			</div>
		</div>
	</header>

	<div id="main" class="site-main">


<div id="main-content" class="main-content">

	<div id="primary" class="content-area">
		<div id="content" class="site-content" role="main">

			<article class="post type-post status-publish format-standard hentry">

	
	<header class="entry-header">

	

		<div class="entry-meta">
			<span class="cat-links">
                
			</span>
		</div>

		<h1 class="entry-title"></h1>

		<div class="entry-meta">
			<span class="entry-date">
				<a href="/post/neatl1-theory//index.html" rel="bookmark">
					<time class="entry-date" datetime="0001-01-01 00:00:00 &#43;0000 UTC">
						January 1
					</time>
				</a>
			</span>
		</div>

	</header>
	
	<div class="entry-content">
		<p>&ndash;
title: &ldquo;NEATL Theory 1: Introducing Neuroeconomics&rdquo;
date: 2017-07-08T16:07:19+09:00
draft: false
categories: [ &ldquo;Theory&rdquo; ]</p>

<h2 id="tags-neatl-theory-cognitive-linguistics-cognitive-science">tags: [ &ldquo;neatl theory&rdquo;, &ldquo;cognitive linguistics&rdquo;, &ldquo;cognitive science&rdquo; ]</h2>

<p><strong>I. Motivations and Goals of NEATL Theory</strong></p>

<p>A Neuroeconomic Approach to Language, what I&rsquo;ll call NEATL Theory, is a number of combined ideas. Most simply, it is an attempt to model and explain
the mechanics of language through the structures, concepts, and approaches of neuroeconomics, a field developed by Paul Glimcher and others.
Neuroeconomics is &ndash; to start with a grossly oversimplifying gist &ndash; a framework using the structure and mechanics of
&ldquo;decision-making&rdquo; cortical maps and their support mechanisms (most importantly meta-action maps) to manifest (and thereby explain) voluntary action
of humans and animals and the (internal) structures and conditions under which it operates.</p>

<p>NEATL Theory doesn&rsquo;t refer to neuroeconomics as it is now, but with some proposed extensions and with the addition
of other approaches, in particular action theory and child development. It is also, at this early point, not really designed
to be a compelte and robust explanatory theory, but more of a roadmap to thinking about the mechanics of language and meaning and all the pieces
that will have to go into it. That is, it offers a way to think about the mechanics of language from an operational perspectie of interconnected
functional mechanisms and not a formal system of symbols, lines, and boxes on paper.</p>

<p>We can then think about using that idealized framework to describe and explain any kind of animal &amp; human activity.
For humans, the most important category of volitional action to construct and explain is language.
Actions do not have purposeful meaning until that structure is in place.
In that respect, the mechanics of NEATL theory, via first language acquisition, offer a way to think about
volition, personal identity, and free will, contrasted to the non-bootstrapped action of other animals and
prelinguistic humans.</p>

<p>The word &ldquo;approach&rdquo; (the A in NEATL) can have three meanings which respond to the needs for a base framework for human action.
The first is that neuroeconomics is not only a set of findings and theories about human action,
it&rsquo;s also a way of thinking about how to study, explain, and talk about categories of human action and volition at all.
One of the core ideas of neuroeconomic methodology is knitting together levels of explanation of human action, such that
higher level phenomena can be explained in terms of lower-level mechanics, and understanding lower-level mechanics according
to their higher-level functions. Each direction guides the other.</p>

<p>The second idea is that neuroeconomics defines a foundation of low-level mechanisms for human action and there is a long road
from that foundation to full-blooded language as a category of action. The approach is then the set of ideas one would need
to get from the neuroeconomic foundation to the linguistic penthouse.<br />
The suggestion is that there are dozens to hundreds of floors to cover, although they are not necessarily heirarchically ordered.</p>

<p>Inside the penthouse is a brand of cognitive linguistics, which may take inspiration from current strains of cog linguistics but
as built independently from the ground-up &ndash; it&rsquo;s mechanics should arise naturally from the mechanics of the underlying floors and not from some other theories top-down.
At best we can try to reconstruct other theories&rsquo; mechanics through the NEATL mechanics. We can call this neuroeconomic linguistics (NEL) to distinguish it from
formal vanilla cognitive linguistics (which is generally not particularly attune to actual cognitive mechanisms).</p>

<p>&ldquo;Approach&rdquo; can have a third meaning which combines the previous two. One core feature of a NEL is that it has built within it
all the lower-levels of mechanics it took to arrive at the theory, and it obliges any
person modeling the meaning of sentences to reconstruct the meaning in terms of that trip to get there, at least in broad relevant strokes,
passing from level to level up to the linguistic practice, each level knit to the next.</p>

<p><strong>A Big Caveat &ndash; General Cognitive Theories in the Time of Skepticism</strong></p>

<p>I&rsquo;m going to make a separate <u>post</u> about why this is a bad time for developing grand general theories of cognition,
and why I am making an effort to talk about one anyway.</p>

<p>Basically, cognitive science is still a relatively recent field. The major findings are across a spectrum of confidence levels.
The findings that seem to have the highest levels of confidence are for rather narrow domains of cognition.
Theories about high-level complex cognition seem to run into familiar problems that, to me, are maybe best characterized by the
exploiding activation problem or &ldquo;completeness&rdquo; problem in AI. So many different mechanisms get activated in tangled and complex ways for general cognition that
it&rsquo;s difficult to disentangle them. And to try to operate or describe the system without disentangling them can crash the system, so to speak.
But to work with toy systems which don&rsquo;t pull in every system leads to either garbage output or sensible output only in the narrowest
of domains. You either have an entire universe of mechanisms interlinked or nothing; it&rsquo;s hard to have general cognition with a theory in between.
So that&rsquo;s one of the major challenges that make it difficult to develop or test theories of general cognition, of which this is one.</p>

<p>I am still interested in developing this project because I think it offers a way of thinking about the issues in a
consistent way, based on a set of general principles that have at least some empirical basis, and seeing how far
we can get building off of them. Second, one thing I liked about Glimcher&rsquo;s work is that he had clever ways of
turning complexity acros domains from a barrier to an asset. Once we have a set of robust findings across different
domains of behavior (economics, behavioral psychology, sociobiology, etc.), we can try to build a theory which tries to consistently
operationalize them. That is, the findings can mutually restrict the mechanisms, until one is left with a good idea of
the kinds of mechanisms that could operate across the domains. To do this kind of practice still takes some interpretion.
One has to be willing to sacrifice some sacred cows (that utility either doesn&rsquo;t exist or cannot be directly measured in economics, that grammar is
an innate structure in Chomskyan-inspired linguistics, that the brain is organized by self-contained modules, etc.) in order
to get the pieces to fit together. But to do that requires one to have opinions about which ideas in domains should be kept and
made consistent with ideas from other domains, and which ones should be sent to the chopping block in order to allow the
domain to be made consistent.</p>

<p>Well-established empirical findings should always be privileged. But moving into findings that
are more complex and difficult to interpret, I think a good strategy is to consider the pieces across various domain as designed
 to be working from the same system, and read them in terms of each other, which suggests consistent approaches that
 wouldn&rsquo;t be as visible if one were looking only from the perspective of one domain. So that&rsquo;s the proposed virtue
 of trying to unify ideas across major fields, in this case, neurophysiology, behavioral psychology, microeconomics,
 and cognitive linguistics. This theory builds off the idea that all of these fields are different levels of explanation of the
 same underlying mechanisms of volitional action in humans. And they each already have general principles which offer ideas about how to integrate them.</p>

<p>I am building this theory by following these principles and ideas with the findings we know.
I am also building off theories developed by others, trying to see how the could be integrated in a shared framework.
I am not confident enough to say this is any kind of revolutionary theory. I think there are enough ideas that
suggest there&rsquo;s a coheasive theory here that I want to develop it from those ideas as best I can.
That&rsquo;s my ultimate goal with this project, to construct a theory out of these principles and ideas that I think
work together. How useful such a theory will be, time will tell.</p>

<p><strong>II. Introducing Neuroeconomics</strong></p>

<p>The neuroeconomics base I want to build from has been developed by Paul Glimcher in his book <em>Foundations of Neuroeconomic Analysis</em>.
So the start of this section will largely be a summary of that work, with me offering observations about the parts which should be useful for
forming the basis of NEATL theory, i.e., serving as the foundations for the higher levels.</p>

<p>As mentioned above, at the base of the theory is activity in cortical maps in the line of transit from afferent (senses up) to efferent (action up) pathways within discrete(ish)
modalities of perception and action, those maps whose activity function as the triggering gatekeepers to action-signals running down efferent pathways to kinematic systems
to ultimately direct action. Following motion-signals running up efferent pathways, one eventually reaches threshold points where action-directing signals originate.
The cortical maps serving as gatekeepers to those last-node pathways are the ones we&rsquo;re interested in here.
 Functionally these are decisionmaking mechanisms, neural mechanisms which create a &ldquo;decision making space&rdquo;, a space one can model geometricly more or less concretely to abstractly,
and act within that space to evaluate the &ldquo;value&rdquo; of decision possibilities according to various considerations, and select a winning
course which is triggered into action and followed-up on. Also included are associated mechanisms, such as coordinated activity across multiple maps, and the set of mechanisms
 registering the activity as a decision to other systems, e.g., the feeling of volition and self-attribution constructed in parallel with the action outputs of the decisions.</p>

<p>Neuroeconomics &ndash; in my understanding and as an oversimplified starting point to unpack &ndash; is a theory about modeling human
decisions from the perspective of the decision-making cortical maps at the ground level of evaluating, selecting, triggering, &amp; following-up on
discrete actions by action modality.</p>

<p>A major part of the theory is developing the models of how these mechanisms operate. But the theory goes further by trying to connect
the operations as the causal, explanatory bases for higher levels of description of human action.
That&rsquo;s why the next theory to add is action theory, the construction of complex, coordinated chains of actions across time, which is the topic of the next chapter.</p>

<p>Before turning to the mechanics of the cortical maps, I want to take a short bird&rsquo;s eye view of the model.</p>

<p>The punchline of the theory is a set of relationships between three levels of analysis, microeconomics, psychology, and neuroscience.</p>

<p>[Three Layer Diagram]</p>

<p>[&hellip;]</p>

<p>One could understand the gist of the theory with this diagram of the relationships among the three levels. The relationship between levels is not best framed as a reduction, but as lower levels providing explanatory power (the top-level theories operate as they do because of the lower level operations; in this way Glimcher calls neuroeconomics a “because” theory) while each level also provides constraints on the other levels. [example]
It is worth spending a moment with the idea of a “because” theory, versus an “as if” theory, as this also plays heavily in linguistics. […] Each level also provides a type of guidance to the other levels. While the lower neuroscience level offers explanatory power and limits what the higher level theory can say, the higher level theory provides the theoretical structure through which one can understand the structure of lower level functions. It provides the higher level forest view to make sense of what the activity of the lower level trees is adding up to, and what to look for. This is keeping with the functional neuroscience approach.
The other reason Glimcher’s model is instructive is that it presents a method in which one first identifies the major theoretical concepts or objects, and then understands the relationships among levels as explicitly linking objects at each level.
Now I will introduce the major pieces of the theory. I will introduce it in layers of complexity.</p>

<p><strong>1. Volitional Cortical Maps</strong></p>

<p>This chapter is going to start with the triggering of individual discrete motions, or as individual and discrete as we can pare the activity on the maps
down to. The triggers for such actions are close to the atomic level of volition, so it&rsquo;s worth spending time with them.
One of the principles that neuroeconomis suggests is that more complex action is compositional, constructed by the coordination of these pre-arranged atoms of action.
This is one way it addresses the classic chunking problem; the problem of defining the most basic units of perception and action and how they combine and coordinate.</p>

<p>[Cross Link to &ldquo;Cortical maps in development&rdquo; page]</p>

<p>To fill that out a bit more, just as &ldquo;gatekeeper&rdquo; mechanisms on the maps for the final signals down efferent pathways define the atoms of action, both volitional and reflexive,
so the units of processing by evaluation mechanisms on structures on these maps which coordinate action scenarios with perceptual elements packaged on the maps
for that purpose define the atoms ofperceptual elements, and in the case of executive maps coordinating action across multiple modalities, something we&rsquo;ll look at later,
the atoms of consciousness qua attention. There are mutliple layers being processed at multiple levels of scale in parallel, though, so it&rsquo;s not designed to
make individual processing mechanics appear recognizable as such.
And because these mechanisms are complex and composite, however, the term &ldquo;atom&rdquo; shouldn&rsquo;t be taken too literally.
It&rsquo;s atomic
from the mechanical perspective of how higher levels of description are constructed and packaged from pieces, but not from the perspective of their own construction; although even here mechanisms such as the [&hellip;MaxArg] are designed to function relatively discretely.</p>

<p>That simple picture is going to be complicated by action modalities that involve sophisticated, composite, coordinated motions as part of the &ldquo;same&rdquo; action, such as
involved with speech (think of the coordination of diaphram, larnyx, toungue, jaw, face, lips, etc., involved in the anunciation of a single phoneme), or with
even simple actions like taking a step, waving one&rsquo;s hand, or simply turning in place. This, again, will be the subject of the next chapter.
This chapter isn&rsquo;t covering &ldquo;single&rdquo; actions like that. It&rsquo;s covering individual, discrete triggers on a cortical map.</p>

<p>The principle is that these discrete triggers are the building blocks that executive mechanisms can package together into more or less arbitrarily packaged
(within limits) units of action, which packages can be triggered as such, as phonemes or set gestures.</p>

<p>If these packages are the &ldquo;atoms&rdquo; of action, selected and triggered as packages, then the decisionmaking map triggers are like the quarks that
are packaged to make them, although sometimes it happens that a single trigger mechanism can serve as its own package. (The package-ability of
action units actually varies by modality as intimated above, saccades package differently than utterances, or leg or arm stretches, etc.)</p>

<p>All of this is rather abstract, so it&rsquo;s good to look at a specific example.
Glimcher&rsquo;s work focuses on decision-making maps for eye saccades.
As far as action modalities go, it is among the most researched, documented, and self-contained.
A single eye saccade can be matched to a single trigger within a single cortical map, with the activity giving the eye muscles
all the information they need to properly move.</p>

<p><strong>2. The Mechanics of Eye Saccades</strong></p>

<p>The bulk of Glimcher&rsquo;s work describes the cortical maps controlling the evaluation, selection, and triggering of eye saccades,
 most substantively by his primate studies, actually measuring activity of individual neurons directly (invasively) and in real-time as
  the primate conducted saccade-based tests, basically simple game-theory economic games like the work-shirk game.
Glimcher&rsquo;s model model system got more hedged and more complicated over time, so even it isn&rsquo;t the perfectly crystallized
 volition platform one would design top-down. (And of course other systems only add to complexity from there.)
 Biology is typically like that. It spreads function out across multiple maps, with redundancy and unclear boundaries and attribution,
 since the maps are heavily interconnected so activity on one induces corresponding activity in the others.
 We shouldn&rsquo;t want to be too quick to dismiss the relevance of the redundancy and ambiguity in function though.</p>

<p>The areas and activity Glimcher looks at are the lateral interparietal nucleus (LIP), [others] as they function in saccade-based economic games.</p>

<p>That said, there is activity which can be viewed as having the function of evaulating the value of possible courses of action,
and mechanisms associated with them that have clear attributability in selecting the most valued course of action
(factoring it with a few other contextal elements, including native randomizing nudges).</p>

<p>It&rsquo;s these &ldquo;evaluative&rdquo; structures and &ldquo;selection&rdquo; mechanisms which Glimcher focuses on. Even if activity is spread across maps, one can hone in on selection mechanisms
as the key mechanism in decisionmaking and volition.
The complexity comes in as layers of activity set up the evaluative platform on which selection occurs.
And one may find multiple layers of inputs into the evaluation and selection activity, just as they send out signals acting on other maps.
But having a single discrete selection mechanism focuses us to the key location for decisionmaking. It&rsquo;s like the hub which
focuses all the messy evaluative activity, factoring decisions across countless considerations, pre- and post-decision, to a small set of decisionmaking platforms
where final decisions are triggered and sent down as action and other mechanisms, such as conscious representation of the decision post-event.</p>

<p>I want to break-down this whole system into three parts, pre-decision evaluation, decision trigger, and post-decision action and representation,
although I am open that these parts may not cleanly align pre-, at, and post-event and may cross boundaries or be fuzzily boundried without clear lines viz. the event.
I am more interested in function and the mechanics of dependence.</p>

<ol>
<li>Evaluation &amp; Decision-making Space<br /></li>
</ol>

<p>In the vision system, there is a sequence of cortical maps representing data about the visual field.
On the afferent end of the trail, activity would represent objects in the visual field. On the efferent
end of the trail, activity would represent a saccadic movement of the eye to bring that area to the center of the field.</p>

<p>Glimcher&rsquo;s narrative about activity on LIP is that it is neither afferent or efferent, neither
representing information about objects in the visual field (since there can be activity in areas where there aren&rsquo;t
objects in vision) nor about movements of the eye (since there can be activity in areas where there isn&rsquo;t motion).
In a series of clever experiments, he concluded that the activity represented roughly the reletive expected utility (which he renamed
&ldquo;subjective value&rdquo; to distinguish it from the mathematical concept in economics).</p>

<p>Glimcher&rsquo;s most useful experiment for understanding the activity was setting up a work/shirk game well studied
in game theory, with the agent being [macquae monkeys with invasive detectors registering their LIP area).
Each round of the game, the agent can choose to work and get a regular small payoff, or
one can choose to shirk (take the day off) and take a risk that the boss is not in the office and receive
a much bigger payoff (still getting paid for the day &amp; the benefits of the day off),
otherwise the boss comes in and the agent receives zero payoff (not getting paid that day).</p>

<p>He set up a screen with a green button (for work) on the lefthand side and red button (for shirk) on the righthand side.
At the start, the agent is instructed to look at the center for 10 seconds, then look at one of the buttons for 10
seconds, after which the payoff comes in the form of a juice shot, either small sized, large sized, or nothing, dependeing on the case.</p>

<p>If one sets up the situation so the shirk move gave the bigger payoff randomly in <sup>1</sup>&frasl;<sub>3</sub> of cases, then the Nash equilibrium
strategy would be to choose the shirk move randomly with a <sup>1</sup>&frasl;<sub>3</sub> probability. Any more than that and one would only be
falling below the payoff of choosing work. The behavior of the [monkey], like humans, quickly converged with the
Nash equilibrium strategy when repeating the game many times. (If one changed the probability of the shirk payoff,
the equilibrium trategy would change and converge over a number of trials.)</p>

<p>The punchline was that the activity of LIP represented the region of each button in correspondence
with the relative expected utility of each option.
First, the areas would light up at the start, when the agent was instructed to look only at the center.
So the activity did not represent instructions to look at either area.
And the button images could actually be removed, keeping the rules of the game (the agent is instructed
to look at the area where it was), and the areas still lit up. So the activity did not represent
 visual objects at those areas.
The work area would have a consistent level of activity.
The shirk area&rsquo;s level of activity varied over rounds of the game.
When the game was a <sup>1</sup>&frasl;<sub>3</sub> payoff scenario, it would light up with a same or greater level
of activity on <sup>1</sup>&frasl;<sub>3</sub> of the rounds, after which the activity would fall below the work level.
There was a stochiatic randomness added to the activity which wobbled the signal and its location
proportional to the size, a mechanism I&rsquo;ll look at in more detail later. [&hellip;]</p>

<ol>
<li>Selection / Decision-Making, Triggers, and their complications</li>
</ol>

<p>At the critical moment of decision, LIP had a selection mechanism triggering the &ldquo;winning&rdquo; move
(the region with the relatively greater activity than the other active options)
and sending it down efferent pathways as instructions for movement.
Part of the selection mechanism was a corresponding mechanism which zeroed out the other regions
activity, leaving only the winning option&rsquo;s activity.</p>

<ol>
<li>Action &amp; Conscious Representation
Aside from a decision sending down instructions to the motor cortex and other systems to plot motion,
there should also be signals to induce a conscious representation of the decision, post-event, as a volitional trigger for attribution purposes,
which nevertheless is properly packaged as part of the same discrete event; since by this point the command is locked in the efferent pathway down to action.
(I think there are dual- or multiple-representation packages as well, the volitional trigger tied to the pre-motion muscle contraction-anticipation tied to the actual muscle
contractions. With something like phonemes, the representation would include the acoustic-packaged-structure, and an analog of volition, anticipation, and muscle contraction tied to it, etc.)
[contra the typical commentary behind the thumb studies which claims decisions aren&rsquo;t free if conscous representation comes later. We&rsquo;ll have to come back to this argument later].</li>
</ol>

<p>[&hellip;]</p>

<ol>
<li>Updating the Subjective Value level for future games.</li>
</ol>

<p><strong>2. Elements of Neuroeconomics</strong></p>

<p>We can give functional interpretations of these mechanisms, and we can also reconstruct decision theory concepts through these mechanics.
With that in mind, I want to consider a number of decisionmaking concepts.</p>

<p>Option Selection.</p>

<p>&ldquo;Evaluation&rdquo;, Comparing relative activity / subjective value.</p>

<p>Payoff &amp; Satisfaction.</p>

<p>&hellip;</p>

<p>&ldquo;Subjective Value&rdquo;</p>

<p>Baselining. Stevens Power Law &amp; the cortial decisionmaking map version.</p>

<p>One way to frame this model is as an expression of the massive modularity thesis (Fodor) via network modality (Morsella).
[…]</p>

<p>At this point, it’s time to walk through the theory objects from the top level formal perspective, describing how the lower level objects explain their operation.
Subjective Values, and Relative Subjective Values. Neuroeconomics distinguishes utility from subjective value. In classic economics, utility was understood as a kind of logical construct loosely representing the value of an object for purposes of choosing that object viz. other objects. In modern economics, this representation gets flipped around, where instead of assuming utility defines choice, choice outlines a utility curve.
“GARP proved that any subject who shows no circularity in her choices behaves exactly as if she were really trying to maximize a weakly monotonic utility function.”  [“A monotonic utility function in this sense is one that goes up as the quantity goes up. It is a utility function that captures the idea ‘more is better.’”] [Weakly monotonic means the function either goes up or is flat, since as one gains more of something (apples), there comes a point where more is not actually better and may be worse. ] GARP does not prove a literal utility curve exists in the mind so much as prove that agents acting non-circularly in their choices behave as if they were following the curve.
Subjective Value (SV) is something much more concrete. It is a real number from 0-1000 representing neural action potentials per second of a neuron or neuron set representing some choice on a decisionmaking platform. SV has a very direct relationship to choice. There are two routes through which neuron activity trigger action or a choice: (1) when the SV of a represented choice crosses a threshold value triggering the represented action or (2) by the SV outranking other proposed choices represented by the SV of other neuron sets with a “winner take all” mechanism (equivalent to a ArgMax mechanism in economics) which triggers the winning action and extinguishes the SV activity of the other proposals, effectively selecting the winning choice for action. Both of these routes are functions of SV strength. As humans make choices according to SV activity, something akin to a monotonic utility curve may emerge; however, using different terms emphasizes that SV and utility are understood and measured by different methods, and they are not necessarily the same. SV is of course the more all-encompassing value in that, as effectively the sine non qua of choice, by definition [ex hypothesi] it is always coterminous with choice. In situations where a classic utility curve and SV differ, it will be SV that will more perfectly represent human choice. Classic economic theory would actually define deviations from a utility curve, or violations of WARP or GARP as deviations from rational behavior, in some sense “wrong” from a normative perspective; and from a descriptive perspective it would simply be without resources to explain the deviation, except as either a ‘just so’  ad hoc explanation constructed just to explain the deviation in terms of utility (which has no empirical ground further than it occurred to and made sense to the author).
SV of course does not allow for deviations or “wrong” choices, because its activity simply is, or is the key part of, the mechanism of choice. It is a fully descriptive theory which, at this primary level of explanation at least, does not offer any normative considerations whether a choice is good or bad for an agent in the short or long run, although it may have considerations to contribute on deeper reflection (we will consider that issue later).
Can we call the method of measuring SV a theory of choice?
One issue, from the perspective of prediction and explanation, is that measuring the SV of neuron sets by itself does not give us an equation of or guidance towards what the SV level will be in various cases. We need to know the information going into the neuron sets which actually lead it to have the SV level it has, or even better the structure of that process. A complete account of that structure would be more properly a theory of SV.
Glimcher’s Foundations offers a number of pieces to this structure, our understanding of which is already good enough to ensure that they will be essential elements however the theory develops.
Many elements fall out of psychophysics.</p>

<p><strong>Stevens Power Law:</strong> power-law fall-off curve of subjective percept intensity of modality (brightness, sweetness, etc.)/neural activity/SV intensity ([Weber-Fechner Law], p. 90),
Transducer biophysics: Relativization of signal</p>

<p><strong>Stociasticity</strong>, two types:
(1) Random Utility Model/Poisson Process: mean &amp; variance increase together; stociasticity/probability increases as intensity increases <a href="2">“As the average inter-spike interval of a Poisson process neuron shrinks, so does its variance, and at exactly the same rate.” (p. 207). “To put all of this more compactly, we can take the ratio of standard deviation to mean, a measure called the “coefficient of variance” (CV). For a Poisson process this number is 1.” (p. 208)</a> Trembling Hand (Selten)/Stochastic Transfer Function. Stochiasticity inherited by transfer from input-systems. P. 216 ff.
…
This provides a better idea of how SV operates in terms of its own mechanics and in terms of its contribution to human choice.
Can we characterize SV in phenomenological terms?
In raising that kind of question, before addressing it head-on, I think it’s important to address a number of caveats to the concept of SV to avoid misunderstanding it.
As will become evident in future chapters, the way we articulate value, or our perceptions of value, in natural language involves a translation process into language, which means it does not exactly represent how SV actually operates.
A step before this, the activity of SV involved in actual decisonmaking also involves a translation into our conscious feeling of “desire” (we will need to be more precise about how to characterize this feeling and its relationship to SV).
Thus it would be prudent from the start to distinguish SV from the way we describe our experience of value in reflecting on some thing in the context of a choice, both in terms of our actual feeling/experience (including perhaps our short term working memory of the feeling or other derivative forms which may be the more relevant elements to our reports on the feeling), and our translation of that experience or possible derivative forms into language. This type of distinction is a common theme throughout this entire work; we will want to make it essentially for every category of experience we have a tradition of explaining in language. (This is the groundwork for a theory of folk psychology.) It will become a critical piece in later chapters as the relationship between SV calls and language utterances about those calls, and the mechanisms that mediate that relationship, will be a foundational element to our theory of language.
These observations raise caveats to the idea that SV represents something that we can fairly call “subjective” (something we internally feel) and “value” (the internally felt pull we have towards the appeal of a thing, within its modality, in the context of a choice to obtain the payoff it offers in that modality, a hit of sweetness or savoryness or the like.).</p>

<p>For now, we should think about SV only in the mechanical terms of the mechanism by which choice is realized within the platform(s) for action selection for a given action modality, and bracket for now any concept of an internal feel of “subjective pull” associated with the SV towards that choice/action, which we will return to later in the context of [Action Theory and later the Language Acquisition Bootstrap, where that concept will play a leading role.]</p>

<p>[Re the old free will problem: could one have acted differently?
Not in the &ldquo;same&rdquo; world, but in an &ldquo;indistinguisable&rdquo; world. Re: stochiacity. Entropy is the number of physical states a system could be
 in physically indistinguishably. The two stociastic systems have a measure of inherit indeterminacy in the result, in two realities indistinguishable in the entropy sense.</p>

<p>………..
[There’s an important space between transducer biophysics to SV. That is a set of mechanisms which connect an expected SVPO payoff by conducting a “move”, within the modality of an action system, to the SVDC strength of the move within the decisonmaking platform of that action system.
There are a number of necessary elements called for here.
One is realizing or recognizing the action as a discrete “move” within the frame of the situation, itself within the domain of the relevant action modality or network of modalities (object manipulation, transportation, etc.)<br />
One might think of a frame heuristically as the “game” or “situation” the agent understands itself within, and within which the action makes sense viz. making progress or some “move” within that frame, that is, within the logic of that frame’s normative structure (heuristically, the rules &amp; norms of the game).
That heuristic is serviceable at this early point, but not very accurate. First, we are speaking pre-linguistic action, the instinctive (but still volitional) action of animals and ourselves in certain situations (D’Amasio’s first level consciousness). So there is no explicit recognition a game one finds oneself in, much less a move within a game. What there is is an orientation of the agent to its environment and various impulses to take action within that environment as oriented-towards, which impulses carry (or have the potential to) the normative structure of the domain and frame within their received or conscious character.
Such an [instinctive] recognition or orientation of the situation is quite diminished from what we would want to call a game or action-situation. It is an environment within which action impulses are received, which impulses have a normative structure within the situation, or rather, the construction of the situation is constructed by the normative structure of the action-impulses themselves. Consistent with our heterarchy principle, we might expect a top-down and bottom-up interplay, as the action-impulses in part construct a situation as recognition of features of a situation in part construct action impulses, and the entire system dynamically develops.
The value of the payoff, as computed by sense transducers, is not the same thing as the strength of the decision-call to achieve the payoff, although there is undoubtably a close association between the two which leads the latter to often conform to the former.
The next is realizing or recognizing the move to have some expected payoff within the frame, or within the normative structure of the frame. (A note on probability: SV does not represent probability per se. It is a value the strength of which is modulated by recent experience of payoffs for the same “move” within the same “game”.)
Glimcher’s cases are rather simple in that a single discrete move (a saccade) is matched with a discrete payoff with some variable probability. The translation from the payoff transducement (as a function by recent experience of success) to SV strength is rather unmediated by other considerations. But what if the payoff is mediated by other elements, such as a sequence of actions before the payoff is achieved. This line of questioning will brings us to the next section on Action Theory.
Before we cover full-blown complex action, we need to address the roles of what we will call (referencing the wider psychology literature) “script”, “frame”, and “domain” even for discrete single actions or moves. The mechanical version developed here is a diminished version from the way these concepts are described in the psychology literature, however.</p>

<p>Neural Activity “Move” Construction on Decisionmaking/Action Platforms
•   Status, Change, and SV
There are certain tasks the mechanisms creating activity on action decisionmaking platforms have to accomplish, with access to certain information.
There has to be a construction of the strength of an expected SV payoff.
We cannot assume a mechanism that receives the strength by fiat.
[transducer]
The logical or normative structure of a “game.”
Glimcher spoke quite a bit about the construction of understanding of the normative structure of a “game.”
[Memory, Concave Power rule with distance back in time, adds up to a rough rule slowly converging to Nash equilibrium.]
This kind of mechanism approaches a dynamic Nash equilibrium sufficiently enough in practice to allow agents to choose action strategies to receive a payoff, with instinctive behavior, close enough to the equilibrium to maximize its payoff.</p>

<p>……………………………………………………………………
•   Preferences. The added marginal strength of a perception X, as X increases, falls off on a power-law curve (such as X^.6 curve). Preference for X, by extension, also falls off on a similar curve. The source of this is the mechanics of transduction, the process where the raw physical signals of X (the number of photos, the number of sugar molecules) is converted into a neural signal (action potentials per second). As X increases, at higher amounts it takes exponentially greater amounts of X to make equivalent increases in one’s perception of it, and by extension one’s preference of it.</p>

<p>•   [Reservation based Search]</p>

<p>•   “Reference”-Based Biases (status quo, entitlement, etc.). Additions and deletions of X are treated differently in terms of the change in strength of the preference (subjective utility), and this change is sensitive to a reference point, a salient amount of X one has in mind and against which one judges the relative difference of a new amount of X. The basic finding is that additions to the baseline are diminished (they feel smaller gains than they actually are) and deletions against the baseline are augmented (they feel like greater losses than they actually are), with the diminishments and augmentations feeling greatest closest to the baseline. (Additions and deletions at much greater levels of scale above or below lose the effect.)</p>

<p>•   Stochasticity. There is a normal curve-like randomness built into decision-making, where expected behavior falls off from a SV utility maximizing move, the curve of which grows in proportion to the scale of the SV utility, called […]. Glimcher introduces two types, one is</p>

<p>•   [RUM]</p>

<p>•   Discounting</p>

<p>•   ArgMax/Choice</p>

<p>•   Subjective Utility</p>

<p>•   [Independence Axiom]</p>

<p>•   Value/Learning</p>

<p>•   Dopamine</p>

<p>On Intentionality</p>

		
	</div>

	<footer class="entry-meta">

		<span class="tag-links">		
			
		</span>
		
		
	</footer>
</article> 

			<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'Chaopolis';
    var disqus_identifier = '\/post\/neatl1-theory\/';
    var disqus_title = '';
    var disqus_url = '\/post\/neatl1-theory\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
		
		</div>

	</div>
	<div id="secondary">

	

	<div id="primary-sidebar" class="primary-sidebar widget-area" role="complementary">
	
	<h1 class="site-description"><em>Mind | Society | Culture</em></h1>
	
		<script type="text/javascript">
    function site_search(obj) {
    	var host = window.location.host;
        obj.q.value = "site:" + host + " " + obj.ss_q.value;
    }
</script>

<aside id="search-3" class="widget widget_search">
	<form role="search" class="search-form" action="//www.google.com/search" method="get" onSubmit="site_search(this)">

	<input name="q" type="hidden" />
	    <label>
	        <span class="screen-reader-text">Search for:</span>
	        <input name="ss_q" type="text" placeholder="Search ..." class="search-field" />
	    </label>
	    <input type="submit" value="Search" class="search-submit" />
	</form>
</aside>

		<aside id="recent-posts-3" class="widget widget_recent_entries">

	
	<h1 class="widget-title">Recent Articles</h1>
		<ul>
			
		</ul>
	
</aside>
		
		<aside id="categories-3" class="widget widget_categories">
	
	<h1 class="widget-title">Categories</h1>

	<ul>
		
		

	</ul>

</aside>

		<aside id="categories-3" class="widget widget_tags">
	
	<h1 class="widget-title">Tags</h1>

	<ul>
		
		

	</ul>

</aside>
		
	</div>

</div>

</div>

		</div>

		<footer id="colophon" class="site-footer" role="contentinfo">

			<div class="site-info">
				<a href="http://gohugo.io">Powered by Hugo</a>
			</div>
		</footer>
	</div>

	<script type='text/javascript' src='/js/functions.js'></script>
</body>
</html>